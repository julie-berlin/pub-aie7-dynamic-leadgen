{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ad46a5b",
   "metadata": {},
   "source": [
    "# Dyamic Lead Gen - Proof of Concept\n",
    "\n",
    "Set up agentic teams.\n",
    "\n",
    "Example data.\n",
    "\n",
    "Trace outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648e0beb",
   "metadata": {},
   "source": [
    "To start, I am just creating multi-step form presentation part and the scoring part of the flow. These are the most important to get right.\n",
    "\n",
    "1. QuestionPresentation Team\n",
    "    - QuestionSelector Agent - Determines next best question(s) based on prior answers and remaining required ones\n",
    "    - Phrasing Agent - Rewrites questions dynamically (based on tone, audience, fatigue signals)\n",
    "    - Engagement Agent - Detects abandonment risk (e.g. too many skips, inactivity) and uses motivational cues\n",
    "\n",
    "2. LeadScoreResponse Team\n",
    "    - LeadScoring Agent - Applies marketer rubric + inferred logic to classify lead as:\n",
    "    ✅ Definite Yes, ⚠️ Needs Review, ❌ Definite No\n",
    "    - Completion Agent: Custom summary & CTA message rendered on thank-you page\n",
    "    - FollowupAgent: Generates personalized email for \"Yes\" and \"Needs Review\" leads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a04e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from typing import Any, Callable, List, Optional, TypedDict, Union\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2a6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "\n",
    "def create_agent(\n",
    "    llm: ChatOpenAI,\n",
    "    tools: list,\n",
    "    system_prompt: str,\n",
    ") -> str:\n",
    "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
    "    system_prompt += (\"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
    "    \" Do not ask for clarification.\"\n",
    "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
    "    \" You are chosen for a reason!\")\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
    "    \"\"\"An LLM-based router.\"\"\"\n",
    "    options = [\"FINISH\"] + members\n",
    "    function_def = {\n",
    "        \"name\": \"route\",\n",
    "        \"description\": \"Select the next role.\",\n",
    "        \"parameters\": {\n",
    "            \"title\": \"routeSchema\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"next\": {\n",
    "                    \"title\": \"Next\",\n",
    "                    \"anyOf\": [\n",
    "                        {\"enum\": options},\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"next\"],\n",
    "        },\n",
    "    }\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Given the conversation above, who should act next?\"\n",
    "                \" Or should we FINISH? Select one of: {options}\",\n",
    "            ),\n",
    "        ]\n",
    "    ).partial(options=str(options), team_members=\", \".join(members))\n",
    "    return (\n",
    "        prompt\n",
    "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "        | JsonOutputFunctionsParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235fc09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "dotenv_path = os.path.join(os.getcwd(), \".env\")\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path)\n",
    "else:\n",
    "    raise FileNotFoundError(f\".env file not found at {dotenv_path}\")\n",
    "\n",
    "# Validate required environment variables\n",
    "REQUIRED_ENV_VARS = [\"LANGCHAIN_API_KEY\", \"OPENAI_API_KEY\"]\n",
    "for env_var in REQUIRED_ENV_VARS:\n",
    "    assert os.getenv(env_var) is not None, f\"Missing required environment variable: {env_var}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables for LangSmith\n",
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"POC JKWB - {uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc49fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set up connection to Supabase\n",
    "# import supabase\n",
    "# from supabase import create_client, Client\n",
    "\n",
    "# # Define Supabase connection constants\n",
    "# SUPABASE_URL_ENV = \"SUPABASE_URL\"\n",
    "# SUPABASE_KEY_ENV = \"SUPABASE_SERVICE_KEY\"\n",
    "\n",
    "# SUPABASE_URL = os.getenv(SUPABASE_URL_ENV)\n",
    "# SUPABASE_SERVICE_KEY = os.getenv(SUPABASE_KEY_ENV)\n",
    "\n",
    "# assert SUPABASE_URL is not None, f\"Missing required environment variable: {SUPABASE_URL_ENV}\"\n",
    "# assert SUPABASE_SERVICE_KEY is not None, f\"Missing required environment variable: {SUPABASE_KEY_ENV}\"\n",
    "\n",
    "# # Initialize Supabase client\n",
    "# supabase_client: Client = create_client(SUPABASE_URL, SUPABASE_SERVICE_KEY)\n",
    "\n",
    "# # Example: List tables in the public schema (for verification)\n",
    "# try:\n",
    "#     response = supabase_client.table(\"pg_tables\").select(\"*\").eq(\"schemaname\", \"public\").execute()\n",
    "#     if hasattr(response, \"data\"):\n",
    "#         table_names = [row[\"tablename\"] for row in response.data]\n",
    "#         print(\"Supabase public tables:\", table_names)\n",
    "#     else:\n",
    "#         print(\"Could not retrieve table list from Supabase.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error connecting to Supabase or listing tables: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools\n",
    "\n",
    "from typing import Annotated, List, Tuple, Union\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# @tool\n",
    "# def retrieve_information(\n",
    "#     query: Annotated[str, \"query to ask the retrieve information tool\"]\n",
    "#     ):\n",
    "#   \"\"\"Use Retrieval Augmented Generation to retrieve information about student loan policies\"\"\"\n",
    "#   return rag_graph.invoke({\"question\" : query})\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "import json\n",
    "from typing import Annotated, Any\n",
    "\n",
    "@tool\n",
    "def retrieve_and_parse_json(\n",
    "    file_path: Annotated[str, \"Path to the JSON file to retrieve and parse\"]\n",
    ") -> Any:\n",
    "    \"\"\"\n",
    "    Retrieve and parse information from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        Any: The parsed JSON data.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the file does not exist.\n",
    "        json.JSONDecodeError: If the file is not valid JSON.\n",
    "        AssertionError: If file_path is not a string or is empty.\n",
    "    \"\"\"\n",
    "    assert isinstance(file_path, str) and file_path.strip(), \"file_path must be a non-empty string\"\n",
    "    try:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "        return data\n",
    "    except FileNotFoundError as fnf_error:\n",
    "        raise FileNotFoundError(f\"JSON file not found: {file_path}\") from fnf_error\n",
    "    except json.JSONDecodeError as json_error:\n",
    "        raise json.JSONDecodeError(f\"Invalid JSON in file: {file_path}\", doc=json_error.doc, pos=json_error.pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafdfe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# team state\n",
    "\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import functools\n",
    "\n",
    "class QuestionPresentationTeamState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    team_members: List[str]\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae847a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_supervisor = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_agent = ChatOpenAI(model=\"gpt-4o-nano\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4666c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create agents and nodes\n",
    "\n",
    "# question selection\n",
    "QUESTION_AGENT_PROMPT = \"\"\"You are a marketing expert.\n",
    "You will pick the best 1-3 questions to ask next. You will consider the answers to the questions already asked, information known about the user from URL query parameters, marketing expert knowledge and the body of possible remaining questions, both required and optional.\n",
    "\"\"\"\n",
    "\n",
    "question_agent = create_agent(\n",
    "    llm_agent,\n",
    "    [], # get questions from data\n",
    "    QUESTION_AGENT_PROMPT,\n",
    ")\n",
    "\n",
    "question_node = functools.partial(agent_node, agent=question_agent, name=\"Questions\")\n",
    "\n",
    "\n",
    "# phrasing of selected questions\n",
    "# this might be best as edge and regular node\n",
    "PHRASING_AGENT_PROMPT = \"\"\"You are a marketing expert.\n",
    "You will examine the questions provided and phrase them in a friendly way to elicit as truthful and complete response as possible.\n",
    "\"\"\"\n",
    "\n",
    "phrasing_agent = create_agent(\n",
    "    llm_agent,\n",
    "    [],\n",
    "    PHRASING_AGENT_PROMPT,\n",
    ")\n",
    "\n",
    "phrasing_node = functools.partial(agent_node, agent=phrasing_agent, name=\"Phrasing\")\n",
    "\n",
    "\n",
    "# check if user still engaged..\n",
    "ENGAGEMENT_AGENT_PROMPT = \"\"\"You are a marketing expert.\n",
    "You will insert some useful and encouraging information for the user into the titles, text paragraphs, and submit button on the page. You seek to ensure the user completes all of the questions and learns about the valueable product or service offered by the business.\n",
    "\"\"\"\n",
    "\n",
    "engagement_agent = create_agent(\n",
    "    llm_agent,\n",
    "    [],\n",
    "    ENGAGEMENT_AGENT_PROMPT,\n",
    ")\n",
    "\n",
    "engagement_node = functools.partial(agent_node, agent=engagement_agent, name=\"Engagement\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create supervisor\n",
    "\n",
    "questions_supervisor_agent = create_team_supervisor(\n",
    "    llm_supervisor,\n",
    "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers: Questions, Phrasing, Engagement. Given the following user request,\"\n",
    "    \" pick the next set of questions and respond with the worker to act next.\"\n",
    "    \" Each worker will perform a task and respond with their results and status.\"\n",
    "    \" You should never ask your team to do anything beyond picking a question, rephrasing a question, or checking engagement.\"\n",
    "    \" When finished, respond with FINISH.\"),\n",
    "    [\"Questions\", \"Phrasing\", \"Engagement\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56854b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_graph = StateGraph(QuestionPresentationTeamState)\n",
    "\n",
    "questions_graph.add_node(\"Questions\", question_node)\n",
    "# questions_graph.add_node(\"LoanRetriever\", research_node)\n",
    "questions_graph.add_node(\"supervisor\", questions_supervisor_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d984b804",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lead score agent\n",
    "SCORING_AGENT_PROMPT = \"\"\"You are a marketing expert.\n",
    "You will examine the questions provided and phrase them in a friendly way to elicit as truthful and complete response as possible.\n",
    "\"\"\"\n",
    "\n",
    "scoring_agent = create_agent(\n",
    "    llm_agent,\n",
    "    [],\n",
    "    SCORING_AGENT_PROMPT,\n",
    ")\n",
    "\n",
    "scoring_node = functools.partial(agent_node, agent=scoring_agent, name=\"LeadScoring\")\n",
    "\n",
    "\n",
    "# completion message agent\n",
    "# todo store results in db\n",
    "RESULT_AGENT_PROMPT = \"\"\"You are a marketing expert.\n",
    "You will examine the questions provided and phrase them in a friendly way to elicit as truthful and complete response as possible.\n",
    "\"\"\"\n",
    "\n",
    "result_agent = create_agent(\n",
    "    llm_agent,\n",
    "    [],\n",
    "    RESULT_AGENT_PROMPT,\n",
    ")\n",
    "\n",
    "result_node = functools.partial(agent_node, agent=result_agent, name=\"ResultMessage\")\n",
    "\n",
    "\n",
    "# follow up message agent\n",
    "FOLLOWUP_AGENT_PROMPT = \"\"\"You are a marketing expert.\n",
    "You will examine the questions provided and phrase them in a friendly way to elicit as truthful and complete response as possible.\n",
    "\"\"\"\n",
    "\n",
    "followup_agent = create_agent(\n",
    "    llm_agent,\n",
    "    [],\n",
    "    FOLLOWUP_AGENT_PROMPT,\n",
    ")\n",
    "\n",
    "result_node = functools.partial(agent_node, agent=followup_agent, name=\"Followup\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c108105",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FollowupTeamState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    team_members: List[str]\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create supervisor\n",
    "\n",
    "followup_supervisor_agent = create_team_supervisor(\n",
    "    llm_supervisor,\n",
    "    (\"You are a supervisor tasked with managing a conversation between the\"\n",
    "    \" following workers: ResultMessage, Followup. Given the following user request,\"\n",
    "    \" pick the next set of questions and respond with the worker to act next.\"\n",
    "    \" Each worker will perform a task and respond with their results and status.\"\n",
    "    \" You should never ask your team to do anything beyond picking a question, rephrasing a question, or checking engagement.\"\n",
    "    \" When finished, respond with FINISH.\"),\n",
    "    [\"Questions\", \"Phrasing\", \"Engagement\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
